{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fab191c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18ff6b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#!pip3 install torch==1.11.0+cu113 torchvision==0.12.0+cu113 torchaudio==0.11.0+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "874c4ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "531e5870",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"liar_plus_dataset/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18b016a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\Project\\\\liar_plus_dataset'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05697ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['id_json', 'label', 'statement', 'subject', \n",
    " 'speaker', 'speaker_job', 'state', 'party', \n",
    " 'barely_true_counts', 'false_counts', 'half_true_counts',\n",
    " 'mostly_true_counts', 'pants_on_fire_counts', 'context', 'justification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "811f81a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"train2.tsv\", sep='\\t', header=None, index_col=0, names=columns)\n",
    "val_data = pd.read_csv('val2.tsv', sep='\\t', header=None, index_col=0, names=columns)\n",
    "test_data = pd.read_csv('test2.tsv', sep='\\t', header=None, index_col=0, names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4057435",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.set_index('id_json',inplace=True)\n",
    "val_data.set_index('id_json',inplace=True)\n",
    "test_data.set_index('id_json',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f36a861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>statement</th>\n",
       "      <th>subject</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speaker_job</th>\n",
       "      <th>state</th>\n",
       "      <th>party</th>\n",
       "      <th>barely_true_counts</th>\n",
       "      <th>false_counts</th>\n",
       "      <th>half_true_counts</th>\n",
       "      <th>mostly_true_counts</th>\n",
       "      <th>pants_on_fire_counts</th>\n",
       "      <th>context</th>\n",
       "      <th>justification</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_json</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2635.json</th>\n",
       "      <td>false</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>dwayne-bohac</td>\n",
       "      <td>State representative</td>\n",
       "      <td>Texas</td>\n",
       "      <td>republican</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a mailer</td>\n",
       "      <td>That's a premise that he fails to back up. Ann...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10540.json</th>\n",
       "      <td>half-true</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>energy,history,job-accomplishments</td>\n",
       "      <td>scott-surovell</td>\n",
       "      <td>State delegate</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>democrat</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a floor speech.</td>\n",
       "      <td>Surovell said the decline of coal \"started whe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324.json</th>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>foreign-policy</td>\n",
       "      <td>barack-obama</td>\n",
       "      <td>President</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>democrat</td>\n",
       "      <td>70.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Denver</td>\n",
       "      <td>Obama said he would have voted against the ame...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123.json</th>\n",
       "      <td>false</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>health-care</td>\n",
       "      <td>blog-posting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>7.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>a news release</td>\n",
       "      <td>The release may have a point that Mikulskis co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9028.json</th>\n",
       "      <td>half-true</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>economy,jobs</td>\n",
       "      <td>charlie-crist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Florida</td>\n",
       "      <td>democrat</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>an interview on CNN</td>\n",
       "      <td>Crist said that the economic \"turnaround start...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  label                                          statement  \\\n",
       "id_json                                                                      \n",
       "2635.json         false  Says the Annies List political group supports ...   \n",
       "10540.json    half-true  When did the decline of coal start? It started...   \n",
       "324.json    mostly-true  Hillary Clinton agrees with John McCain \"by vo...   \n",
       "1123.json         false  Health care reform legislation is likely to ma...   \n",
       "9028.json     half-true  The economic turnaround started at the end of ...   \n",
       "\n",
       "                                       subject         speaker  \\\n",
       "id_json                                                          \n",
       "2635.json                             abortion    dwayne-bohac   \n",
       "10540.json  energy,history,job-accomplishments  scott-surovell   \n",
       "324.json                        foreign-policy    barack-obama   \n",
       "1123.json                          health-care    blog-posting   \n",
       "9028.json                         economy,jobs   charlie-crist   \n",
       "\n",
       "                     speaker_job     state       party  barely_true_counts  \\\n",
       "id_json                                                                      \n",
       "2635.json   State representative     Texas  republican                 0.0   \n",
       "10540.json        State delegate  Virginia    democrat                 0.0   \n",
       "324.json               President  Illinois    democrat                70.0   \n",
       "1123.json                    NaN       NaN        none                 7.0   \n",
       "9028.json                    NaN   Florida    democrat                15.0   \n",
       "\n",
       "            false_counts  half_true_counts  mostly_true_counts  \\\n",
       "id_json                                                          \n",
       "2635.json            1.0               0.0                 0.0   \n",
       "10540.json           0.0               1.0                 1.0   \n",
       "324.json            71.0             160.0               163.0   \n",
       "1123.json           19.0               3.0                 5.0   \n",
       "9028.json            9.0              20.0                19.0   \n",
       "\n",
       "            pants_on_fire_counts              context  \\\n",
       "id_json                                                 \n",
       "2635.json                    0.0             a mailer   \n",
       "10540.json                   0.0      a floor speech.   \n",
       "324.json                     9.0               Denver   \n",
       "1123.json                   44.0       a news release   \n",
       "9028.json                    2.0  an interview on CNN   \n",
       "\n",
       "                                                justification  \n",
       "id_json                                                        \n",
       "2635.json   That's a premise that he fails to back up. Ann...  \n",
       "10540.json  Surovell said the decline of coal \"started whe...  \n",
       "324.json    Obama said he would have voted against the ame...  \n",
       "1123.json   The release may have a point that Mikulskis co...  \n",
       "9028.json   Crist said that the economic \"turnaround start...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66330a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>statement</th>\n",
       "      <th>subject</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speaker_job</th>\n",
       "      <th>state</th>\n",
       "      <th>party</th>\n",
       "      <th>barely_true_counts</th>\n",
       "      <th>false_counts</th>\n",
       "      <th>half_true_counts</th>\n",
       "      <th>mostly_true_counts</th>\n",
       "      <th>pants_on_fire_counts</th>\n",
       "      <th>context</th>\n",
       "      <th>justification</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_json</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12134.json</th>\n",
       "      <td>barely-true</td>\n",
       "      <td>We have less Americans working now than in the...</td>\n",
       "      <td>economy,jobs</td>\n",
       "      <td>vicky-hartzler</td>\n",
       "      <td>U.S. Representative</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>republican</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>an interview with ABC17 News</td>\n",
       "      <td>However, Hartzler was talking about the entire...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238.json</th>\n",
       "      <td>pants-fire</td>\n",
       "      <td>When Obama was sworn into office, he DID NOT u...</td>\n",
       "      <td>obama-birth-certificate,religion</td>\n",
       "      <td>chain-email</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>11</td>\n",
       "      <td>43</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>105</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ellison used a Koran that once belonged to Tho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7891.json</th>\n",
       "      <td>false</td>\n",
       "      <td>Says Having organizations parading as being so...</td>\n",
       "      <td>campaign-finance,congress,taxes</td>\n",
       "      <td>earl-blumenauer</td>\n",
       "      <td>U.S. representative</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>democrat</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>a U.S. Ways and Means hearing</td>\n",
       "      <td>However, we have two professors who say the la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8169.json</th>\n",
       "      <td>half-true</td>\n",
       "      <td>Says nearly half of Oregons children are poor.</td>\n",
       "      <td>poverty</td>\n",
       "      <td>jim-francesconi</td>\n",
       "      <td>Member of the State Board of Higher Education</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>an opinion article</td>\n",
       "      <td>In fact, if you use federal definitions for po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929.json</th>\n",
       "      <td>half-true</td>\n",
       "      <td>On attacks by Republicans that various program...</td>\n",
       "      <td>economy,stimulus</td>\n",
       "      <td>barack-obama</td>\n",
       "      <td>President</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>democrat</td>\n",
       "      <td>70</td>\n",
       "      <td>71</td>\n",
       "      <td>160</td>\n",
       "      <td>163</td>\n",
       "      <td>9</td>\n",
       "      <td>interview with CBS News</td>\n",
       "      <td>Obama's point is that some perspective is in o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  label                                          statement  \\\n",
       "id_json                                                                      \n",
       "12134.json  barely-true  We have less Americans working now than in the...   \n",
       "238.json     pants-fire  When Obama was sworn into office, he DID NOT u...   \n",
       "7891.json         false  Says Having organizations parading as being so...   \n",
       "8169.json     half-true     Says nearly half of Oregons children are poor.   \n",
       "929.json      half-true  On attacks by Republicans that various program...   \n",
       "\n",
       "                                     subject          speaker  \\\n",
       "id_json                                                         \n",
       "12134.json                      economy,jobs   vicky-hartzler   \n",
       "238.json    obama-birth-certificate,religion      chain-email   \n",
       "7891.json    campaign-finance,congress,taxes  earl-blumenauer   \n",
       "8169.json                            poverty  jim-francesconi   \n",
       "929.json                    economy,stimulus     barack-obama   \n",
       "\n",
       "                                              speaker_job     state  \\\n",
       "id_json                                                               \n",
       "12134.json                            U.S. Representative  Missouri   \n",
       "238.json                                              NaN       NaN   \n",
       "7891.json                             U.S. representative    Oregon   \n",
       "8169.json   Member of the State Board of Higher Education    Oregon   \n",
       "929.json                                        President  Illinois   \n",
       "\n",
       "                 party  barely_true_counts  false_counts  half_true_counts  \\\n",
       "id_json                                                                      \n",
       "12134.json  republican                   1             0                 1   \n",
       "238.json          none                  11            43                 8   \n",
       "7891.json     democrat                   0             1                 1   \n",
       "8169.json         none                   0             1                 1   \n",
       "929.json      democrat                  70            71               160   \n",
       "\n",
       "            mostly_true_counts  pants_on_fire_counts  \\\n",
       "id_json                                                \n",
       "12134.json                   0                     0   \n",
       "238.json                     5                   105   \n",
       "7891.json                    1                     0   \n",
       "8169.json                    1                     0   \n",
       "929.json                   163                     9   \n",
       "\n",
       "                                  context  \\\n",
       "id_json                                     \n",
       "12134.json   an interview with ABC17 News   \n",
       "238.json                              NaN   \n",
       "7891.json   a U.S. Ways and Means hearing   \n",
       "8169.json              an opinion article   \n",
       "929.json          interview with CBS News   \n",
       "\n",
       "                                                justification  \n",
       "id_json                                                        \n",
       "12134.json  However, Hartzler was talking about the entire...  \n",
       "238.json    Ellison used a Koran that once belonged to Tho...  \n",
       "7891.json   However, we have two professors who say the la...  \n",
       "8169.json   In fact, if you use federal definitions for po...  \n",
       "929.json    Obama's point is that some perspective is in o...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28cabb79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>statement</th>\n",
       "      <th>subject</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speaker_job</th>\n",
       "      <th>state</th>\n",
       "      <th>party</th>\n",
       "      <th>barely_true_counts</th>\n",
       "      <th>false_counts</th>\n",
       "      <th>half_true_counts</th>\n",
       "      <th>mostly_true_counts</th>\n",
       "      <th>pants_on_fire_counts</th>\n",
       "      <th>context</th>\n",
       "      <th>justification</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_json</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11972.json</th>\n",
       "      <td>true</td>\n",
       "      <td>Building a wall on the U.S.-Mexico border will...</td>\n",
       "      <td>immigration</td>\n",
       "      <td>rick-perry</td>\n",
       "      <td>Governor</td>\n",
       "      <td>Texas</td>\n",
       "      <td>republican</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>42</td>\n",
       "      <td>23</td>\n",
       "      <td>18</td>\n",
       "      <td>Radio interview</td>\n",
       "      <td>Meantime, engineering experts agree the wall w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11685.json</th>\n",
       "      <td>false</td>\n",
       "      <td>Wisconsin is on pace to double the number of l...</td>\n",
       "      <td>jobs</td>\n",
       "      <td>katrina-shankland</td>\n",
       "      <td>State representative</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>democrat</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a news conference</td>\n",
       "      <td>She cited layoff notices received by the state...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11096.json</th>\n",
       "      <td>false</td>\n",
       "      <td>Says John McCain has done nothing to help the ...</td>\n",
       "      <td>military,veterans,voting-record</td>\n",
       "      <td>donald-trump</td>\n",
       "      <td>President-Elect</td>\n",
       "      <td>New York</td>\n",
       "      <td>republican</td>\n",
       "      <td>63</td>\n",
       "      <td>114</td>\n",
       "      <td>51</td>\n",
       "      <td>37</td>\n",
       "      <td>61</td>\n",
       "      <td>comments on ABC's This Week.</td>\n",
       "      <td>Trump said that McCain \"has done nothing to he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5209.json</th>\n",
       "      <td>half-true</td>\n",
       "      <td>Suzanne Bonamici supports a plan that will cut...</td>\n",
       "      <td>medicare,message-machine-2012,campaign-adverti...</td>\n",
       "      <td>rob-cornilles</td>\n",
       "      <td>consultant</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>republican</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>a radio show</td>\n",
       "      <td>But spending still goes up. In addition, many ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9524.json</th>\n",
       "      <td>pants-fire</td>\n",
       "      <td>When asked by a reporter whether hes at the ce...</td>\n",
       "      <td>campaign-finance,legal-issues,campaign-adverti...</td>\n",
       "      <td>state-democratic-party-wisconsin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>democrat</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>a web video</td>\n",
       "      <td>Our rating A Democratic Party web video making...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 label                                          statement  \\\n",
       "id_json                                                                     \n",
       "11972.json        true  Building a wall on the U.S.-Mexico border will...   \n",
       "11685.json       false  Wisconsin is on pace to double the number of l...   \n",
       "11096.json       false  Says John McCain has done nothing to help the ...   \n",
       "5209.json    half-true  Suzanne Bonamici supports a plan that will cut...   \n",
       "9524.json   pants-fire  When asked by a reporter whether hes at the ce...   \n",
       "\n",
       "                                                      subject  \\\n",
       "id_json                                                         \n",
       "11972.json                                        immigration   \n",
       "11685.json                                               jobs   \n",
       "11096.json                    military,veterans,voting-record   \n",
       "5209.json   medicare,message-machine-2012,campaign-adverti...   \n",
       "9524.json   campaign-finance,legal-issues,campaign-adverti...   \n",
       "\n",
       "                                     speaker           speaker_job      state  \\\n",
       "id_json                                                                         \n",
       "11972.json                        rick-perry              Governor      Texas   \n",
       "11685.json                 katrina-shankland  State representative  Wisconsin   \n",
       "11096.json                      donald-trump       President-Elect   New York   \n",
       "5209.json                      rob-cornilles            consultant     Oregon   \n",
       "9524.json   state-democratic-party-wisconsin                   NaN  Wisconsin   \n",
       "\n",
       "                 party  barely_true_counts  false_counts  half_true_counts  \\\n",
       "id_json                                                                      \n",
       "11972.json  republican                  30            30                42   \n",
       "11685.json    democrat                   2             1                 0   \n",
       "11096.json  republican                  63           114                51   \n",
       "5209.json   republican                   1             1                 3   \n",
       "9524.json     democrat                   5             7                 2   \n",
       "\n",
       "            mostly_true_counts  pants_on_fire_counts  \\\n",
       "id_json                                                \n",
       "11972.json                  23                    18   \n",
       "11685.json                   0                     0   \n",
       "11096.json                  37                    61   \n",
       "5209.json                    1                     1   \n",
       "9524.json                    2                     7   \n",
       "\n",
       "                                 context  \\\n",
       "id_json                                    \n",
       "11972.json               Radio interview   \n",
       "11685.json             a news conference   \n",
       "11096.json  comments on ABC's This Week.   \n",
       "5209.json                   a radio show   \n",
       "9524.json                    a web video   \n",
       "\n",
       "                                                justification  \n",
       "id_json                                                        \n",
       "11972.json  Meantime, engineering experts agree the wall w...  \n",
       "11685.json  She cited layoff notices received by the state...  \n",
       "11096.json  Trump said that McCain \"has done nothing to he...  \n",
       "5209.json   But spending still goes up. In addition, many ...  \n",
       "9524.json   Our rating A Democratic Party web video making...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8cb45b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10242, 14) (1284, 14) (1267, 14)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape, val_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2885273",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_na = pd.DataFrame(train_data.isnull().sum(), columns=['NAinTrain']).join(\n",
    "    pd.DataFrame(val_data.isnull().sum(), columns=['NAinVal']).join(\n",
    "        pd.DataFrame(test_data.isnull().sum(), columns=['NAinTest'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1bc0cdca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      NAinTrain  NAinVal  NAinTest\n",
      "label                         2        0         0\n",
      "statement                     2        0         0\n",
      "subject                       4        0         0\n",
      "speaker                       4        0         0\n",
      "speaker_job                2899      345       325\n",
      "state                      2210      279       262\n",
      "party                         4        0         0\n",
      "barely_true_counts            4        0         0\n",
      "false_counts                  4        0         0\n",
      "half_true_counts              4        0         0\n",
      "mostly_true_counts            4        0         0\n",
      "pants_on_fire_counts          4        0         0\n",
      "context                     104       12        17\n",
      "justification                88        4         9\n"
     ]
    }
   ],
   "source": [
    "print(data_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f97e9af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      NAinTrain  NAinVal  NAinTest\n",
      "label                         0        0         0\n",
      "statement                     0        0         0\n",
      "subject                       2        0         0\n",
      "speaker                       2        0         0\n",
      "speaker_job                2897      345       325\n",
      "state                      2208      279       262\n",
      "party                         2        0         0\n",
      "barely_true_counts            2        0         0\n",
      "false_counts                  2        0         0\n",
      "half_true_counts              2        0         0\n",
      "mostly_true_counts            2        0         0\n",
      "pants_on_fire_counts          2        0         0\n",
      "context                     102       12        17\n",
      "justification                86        4         9\n"
     ]
    }
   ],
   "source": [
    "# Dropping records where label in NA in Train \n",
    "train_data.dropna(subset=['label'],inplace=True)\n",
    "# Viewing updated NA Dataframe \n",
    "data_na_1 = pd.DataFrame(train_data.isnull().sum(), columns=['NAinTrain']).join(\n",
    "    pd.DataFrame(val_data.isnull().sum(), columns=['NAinVal']).join(\n",
    "        pd.DataFrame(test_data.isnull().sum(), columns=['NAinTest'])))\n",
    "print(data_na_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b91a2481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      NAinTrain  NAinVal  NAinTest\n",
      "label                         0        0         0\n",
      "statement                     0        0         0\n",
      "subject                       0        0         0\n",
      "speaker                       0        0         0\n",
      "speaker_job                2895      345       325\n",
      "state                      2206      279       262\n",
      "party                         0        0         0\n",
      "barely_true_counts            0        0         0\n",
      "false_counts                  0        0         0\n",
      "half_true_counts              0        0         0\n",
      "mostly_true_counts            0        0         0\n",
      "pants_on_fire_counts          0        0         0\n",
      "context                     100       12        17\n",
      "justification                84        4         9\n"
     ]
    }
   ],
   "source": [
    "# Dropping Records where the all the count flags are NA in train data \n",
    "train_data.dropna(subset=['barely_true_counts'],inplace=True)\n",
    "# Viewing Updated NA Dataframe \n",
    "data_na_2 = pd.DataFrame(train_data.isnull().sum(), columns=['NAinTrain']).join(\n",
    "    pd.DataFrame(val_data.isnull().sum(), columns=['NAinVal']).join(\n",
    "        pd.DataFrame(test_data.isnull().sum(), columns=['NAinTest'])))\n",
    "print(data_na_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ce648cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing all NA with \"\" (Empty space) speaker_job\n",
    "train_data.speaker_job.fillna(\"\", inplace=True)\n",
    "val_data.speaker_job.fillna(\"\", inplace=True)\n",
    "test_data.speaker_job.fillna(\"\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74c9be02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing all NA with \"\" (Empty space) state\n",
    "train_data.state.fillna(\"\", inplace=True)\n",
    "val_data.state.fillna(\"\", inplace=True)\n",
    "test_data.state.fillna(\"\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "097202eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing all NA with \"\" (Empty space) Context\n",
    "train_data.context.fillna(\"\", inplace=True)\n",
    "val_data.context.fillna(\"\", inplace=True)\n",
    "test_data.context.fillna(\"\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2d0668e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing all NA with \"\" (Empty space) Justification\n",
    "train_data.justification.fillna(\"\", inplace=True)\n",
    "val_data.justification.fillna(\"\", inplace=True)\n",
    "test_data.justification.fillna(\"\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55bb4157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      NAinTrain  NAinVal  NAinTest\n",
      "label                         0        0         0\n",
      "statement                     0        0         0\n",
      "subject                       0        0         0\n",
      "speaker                       0        0         0\n",
      "speaker_job                   0        0         0\n",
      "state                         0        0         0\n",
      "party                         0        0         0\n",
      "barely_true_counts            0        0         0\n",
      "false_counts                  0        0         0\n",
      "half_true_counts              0        0         0\n",
      "mostly_true_counts            0        0         0\n",
      "pants_on_fire_counts          0        0         0\n",
      "context                       0        0         0\n",
      "justification                 0        0         0\n"
     ]
    }
   ],
   "source": [
    "# Viewing Updated NA Dataframe \n",
    "data_na_3 = pd.DataFrame(train_data.isnull().sum(), columns=['NAinTrain']).join(\n",
    "    pd.DataFrame(val_data.isnull().sum(), columns=['NAinVal']).join(\n",
    "        pd.DataFrame(test_data.isnull().sum(), columns=['NAinTest'])))\n",
    "print(data_na_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43f34fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling the State column anamolies \n",
    "train_data.loc[train_data.state.isin(['None', 'Unknown']), 'state'] = ''\n",
    "train_data.loc[train_data.state.isin(['Tennesse']), 'state'] = 'Tennessee'\n",
    "train_data.loc[train_data.state.isin(['PA - Pennsylvania']), 'state'] = 'Pennsylvania'\n",
    "train_data.loc[train_data.state.isin(['Rhode island']), 'state'] = 'Rhode Island'\n",
    "train_data.loc[train_data.state.isin(['Tex']), 'state'] = 'Texas'\n",
    "train_data.loc[train_data.state.isin(['Virgiia','Virgina', 'Virginia director, Coalition to Stop Gun Violence']), 'state'] = 'Virginia'\n",
    "train_data.loc[train_data.state.isin(['Washington D.C.','Washington DC','Washington state', 'Washington, D.C.',]), 'state'] = 'Washington'\n",
    "\n",
    "val_data.loc[val_data.state.isin(['None', 'Unknown']), 'state'] = ''\n",
    "val_data.loc[val_data.state.isin(['Tennesse']), 'state'] = 'Tennessee'\n",
    "val_data.loc[val_data.state.isin(['PA - Pennsylvania']), 'state'] = 'Pennsylvania'\n",
    "val_data.loc[val_data.state.isin(['Rhode island']), 'state'] = 'Rhode Island'\n",
    "val_data.loc[val_data.state.isin(['Tex']), 'state'] = 'Texas'\n",
    "val_data.loc[val_data.state.isin(['Virgiia','Virgina', 'Virginia director, Coalition to Stop Gun Violence']), 'state'] = 'Virginia'\n",
    "val_data.loc[val_data.state.isin(['Washington D.C.','Washington DC','Washington state', 'Washington, D.C.',]), 'state'] = 'Washington'\n",
    "\n",
    "\n",
    "val_data.loc[val_data.state.isin(['None', 'Unknown']), 'state'] = ''\n",
    "val_data.loc[val_data.state.isin(['Tennesse']), 'state'] = 'Tennessee'\n",
    "val_data.loc[val_data.state.isin(['PA - Pennsylvania']), 'state'] = 'Pennsylvania'\n",
    "val_data.loc[val_data.state.isin(['Rhode island']), 'state'] = 'Rhode Island'\n",
    "val_data.loc[val_data.state.isin(['Tex']), 'state'] = 'Texas'\n",
    "val_data.loc[val_data.state.isin(['Virgiia','Virgina', 'Virginia director, Coalition to Stop Gun Violence']), 'state'] = 'Virginia'\n",
    "val_data.loc[val_data.state.isin(['Washington D.C.','Washington DC','Washington state', 'Washington, D.C.',]), 'state'] = 'Washington'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "80a45d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv(\"train2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1efef5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Text'] = train_data['statement'].map(str) + train_data['justification'].map(str)\n",
    "val_data['Text']   = val_data['statement'].map(str) + val_data['justification'].map(str)\n",
    "test_data['Text']  = test_data['statement'].map(str) + test_data['justification'].map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e99a3d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.drop(labels=['statement','justification'],axis=1)\n",
    "val_data   = val_data.drop(labels=['statement','justification'],axis=1)\n",
    "test_data  = test_data.drop(labels=['statement','justification'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bf01b742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id_json\n",
       "12134.json    We have less Americans working now than in the...\n",
       "238.json      When Obama was sworn into office, he DID NOT u...\n",
       "7891.json     Says Having organizations parading as being so...\n",
       "8169.json     Says nearly half of Oregons children are poor....\n",
       "929.json      On attacks by Republicans that various program...\n",
       "                                    ...                        \n",
       "3419.json     For the first time in more than a decade, impo...\n",
       "12548.json    Says Donald Trump has bankrupted his companies...\n",
       "401.json      John McCain and George Bush have \"absolutely n...\n",
       "1055.json     A new poll shows 62 percent support the presid...\n",
       "9117.json     No one claims the report vindicating New Jerse...\n",
       "Name: Text, Length: 1284, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "31e7606c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b48a707e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = le.fit_transform(train_data['label'])\n",
    "Y_val   = le.fit_transform(val_data['label'])\n",
    "Y_test  = le.fit_transform(test_data['label'])\n",
    "#le.inverse_transform(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "43f789ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "#le.inverse_transform(Y_train)\n",
    "#le.inverse_transform(Y_val)\n",
    "#le.inverse_transform(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "82e33a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.drop(labels=['label'],axis=1)\n",
    "X_val   = val_data.drop(labels=['label'],axis=1)\n",
    "X_test  = test_data.drop(labels=['label'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3b0a6dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " X Train Data \n",
      "                                       subject         speaker  \\\n",
      "id_json                                                          \n",
      "2635.json                             abortion    dwayne-bohac   \n",
      "10540.json  energy,history,job-accomplishments  scott-surovell   \n",
      "324.json                        foreign-policy    barack-obama   \n",
      "1123.json                          health-care    blog-posting   \n",
      "9028.json                         economy,jobs   charlie-crist   \n",
      "\n",
      "                     speaker_job     state       party  barely_true_counts  \\\n",
      "id_json                                                                      \n",
      "2635.json   State representative     Texas  republican                 0.0   \n",
      "10540.json        State delegate  Virginia    democrat                 0.0   \n",
      "324.json               President  Illinois    democrat                70.0   \n",
      "1123.json                                         none                 7.0   \n",
      "9028.json                          Florida    democrat                15.0   \n",
      "\n",
      "            false_counts  half_true_counts  mostly_true_counts  \\\n",
      "id_json                                                          \n",
      "2635.json            1.0               0.0                 0.0   \n",
      "10540.json           0.0               1.0                 1.0   \n",
      "324.json            71.0             160.0               163.0   \n",
      "1123.json           19.0               3.0                 5.0   \n",
      "9028.json            9.0              20.0                19.0   \n",
      "\n",
      "            pants_on_fire_counts              context  \\\n",
      "id_json                                                 \n",
      "2635.json                    0.0             a mailer   \n",
      "10540.json                   0.0      a floor speech.   \n",
      "324.json                     9.0               Denver   \n",
      "1123.json                   44.0       a news release   \n",
      "9028.json                    2.0  an interview on CNN   \n",
      "\n",
      "                                                         Text  \n",
      "id_json                                                        \n",
      "2635.json   Says the Annies List political group supports ...  \n",
      "10540.json  When did the decline of coal start? It started...  \n",
      "324.json    Hillary Clinton agrees with John McCain \"by vo...  \n",
      "1123.json   Health care reform legislation is likely to ma...  \n",
      "9028.json   The economic turnaround started at the end of ...  \n",
      " X Val Data \n",
      "                                     subject          speaker  \\\n",
      "id_json                                                         \n",
      "12134.json                      economy,jobs   vicky-hartzler   \n",
      "238.json    obama-birth-certificate,religion      chain-email   \n",
      "7891.json    campaign-finance,congress,taxes  earl-blumenauer   \n",
      "8169.json                            poverty  jim-francesconi   \n",
      "929.json                    economy,stimulus     barack-obama   \n",
      "\n",
      "                                              speaker_job     state  \\\n",
      "id_json                                                               \n",
      "12134.json                            U.S. Representative  Missouri   \n",
      "238.json                                                              \n",
      "7891.json                             U.S. representative    Oregon   \n",
      "8169.json   Member of the State Board of Higher Education    Oregon   \n",
      "929.json                                        President  Illinois   \n",
      "\n",
      "                 party  barely_true_counts  false_counts  half_true_counts  \\\n",
      "id_json                                                                      \n",
      "12134.json  republican                   1             0                 1   \n",
      "238.json          none                  11            43                 8   \n",
      "7891.json     democrat                   0             1                 1   \n",
      "8169.json         none                   0             1                 1   \n",
      "929.json      democrat                  70            71               160   \n",
      "\n",
      "            mostly_true_counts  pants_on_fire_counts  \\\n",
      "id_json                                                \n",
      "12134.json                   0                     0   \n",
      "238.json                     5                   105   \n",
      "7891.json                    1                     0   \n",
      "8169.json                    1                     0   \n",
      "929.json                   163                     9   \n",
      "\n",
      "                                  context  \\\n",
      "id_json                                     \n",
      "12134.json   an interview with ABC17 News   \n",
      "238.json                                    \n",
      "7891.json   a U.S. Ways and Means hearing   \n",
      "8169.json              an opinion article   \n",
      "929.json          interview with CBS News   \n",
      "\n",
      "                                                         Text  \n",
      "id_json                                                        \n",
      "12134.json  We have less Americans working now than in the...  \n",
      "238.json    When Obama was sworn into office, he DID NOT u...  \n",
      "7891.json   Says Having organizations parading as being so...  \n",
      "8169.json   Says nearly half of Oregons children are poor....  \n",
      "929.json    On attacks by Republicans that various program...  \n",
      " X Test Data \n",
      "                                                      subject  \\\n",
      "id_json                                                         \n",
      "11972.json                                        immigration   \n",
      "11685.json                                               jobs   \n",
      "11096.json                    military,veterans,voting-record   \n",
      "5209.json   medicare,message-machine-2012,campaign-adverti...   \n",
      "9524.json   campaign-finance,legal-issues,campaign-adverti...   \n",
      "\n",
      "                                     speaker           speaker_job      state  \\\n",
      "id_json                                                                         \n",
      "11972.json                        rick-perry              Governor      Texas   \n",
      "11685.json                 katrina-shankland  State representative  Wisconsin   \n",
      "11096.json                      donald-trump       President-Elect   New York   \n",
      "5209.json                      rob-cornilles            consultant     Oregon   \n",
      "9524.json   state-democratic-party-wisconsin                        Wisconsin   \n",
      "\n",
      "                 party  barely_true_counts  false_counts  half_true_counts  \\\n",
      "id_json                                                                      \n",
      "11972.json  republican                  30            30                42   \n",
      "11685.json    democrat                   2             1                 0   \n",
      "11096.json  republican                  63           114                51   \n",
      "5209.json   republican                   1             1                 3   \n",
      "9524.json     democrat                   5             7                 2   \n",
      "\n",
      "            mostly_true_counts  pants_on_fire_counts  \\\n",
      "id_json                                                \n",
      "11972.json                  23                    18   \n",
      "11685.json                   0                     0   \n",
      "11096.json                  37                    61   \n",
      "5209.json                    1                     1   \n",
      "9524.json                    2                     7   \n",
      "\n",
      "                                 context  \\\n",
      "id_json                                    \n",
      "11972.json               Radio interview   \n",
      "11685.json             a news conference   \n",
      "11096.json  comments on ABC's This Week.   \n",
      "5209.json                   a radio show   \n",
      "9524.json                    a web video   \n",
      "\n",
      "                                                         Text  \n",
      "id_json                                                        \n",
      "11972.json  Building a wall on the U.S.-Mexico border will...  \n",
      "11685.json  Wisconsin is on pace to double the number of l...  \n",
      "11096.json  Says John McCain has done nothing to help the ...  \n",
      "5209.json   Suzanne Bonamici supports a plan that will cut...  \n",
      "9524.json   When asked by a reporter whether hes at the ce...  \n"
     ]
    }
   ],
   "source": [
    "print(\" X Train Data \")\n",
    "print(X_train.head())\n",
    "print(\" X Val Data \")\n",
    "print(X_val.head())\n",
    "print(\" X Test Data \")\n",
    "print(X_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d9271bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " X Train Columns\n",
      "Index(['subject', 'speaker', 'speaker_job', 'state', 'party',\n",
      "       'barely_true_counts', 'false_counts', 'half_true_counts',\n",
      "       'mostly_true_counts', 'pants_on_fire_counts', 'context', 'Text'],\n",
      "      dtype='object')\n",
      " X Val Columns \n",
      "Index(['subject', 'speaker', 'speaker_job', 'state', 'party',\n",
      "       'barely_true_counts', 'false_counts', 'half_true_counts',\n",
      "       'mostly_true_counts', 'pants_on_fire_counts', 'context', 'Text'],\n",
      "      dtype='object')\n",
      " X Test Columns \n",
      "Index(['subject', 'speaker', 'speaker_job', 'state', 'party',\n",
      "       'barely_true_counts', 'false_counts', 'half_true_counts',\n",
      "       'mostly_true_counts', 'pants_on_fire_counts', 'context', 'Text'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\" X Train Columns\")\n",
    "print(X_train.columns)\n",
    "print(\" X Val Columns \")\n",
    "print(X_val.columns)\n",
    "print(\" X Test Columns \")\n",
    "print(X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3333977",
   "metadata": {},
   "source": [
    "CONTRACTION_MAP = {\n",
    "\"ain't\": \"is not\",\n",
    "\"aren't\": \"are not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he will\",\n",
    "\"he'll've\": \"he he will have\",\n",
    "\"he's\": \"he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'd'y\": \"how do you\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how is\",\n",
    "\"i'd\": \"i would\",\n",
    "\"i'd've\": \"i would have\",\n",
    "\"i'll\": \"i will\",\n",
    "\"i'll've\": \"i will have\",\n",
    "\"i'm\": \"i am\",\n",
    "\"i've\": \"i have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it would\",\n",
    "\"it'd've\": \"it would have\",\n",
    "\"it'll\": \"it will\",\n",
    "\"it'll've\": \"it will have\",\n",
    "\"it's\": \"it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"mightn't've\": \"might not have\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"mustn't've\": \"must not have\",\n",
    "\"needn't\": \"need not\",\n",
    "\"needn't've\": \"need not have\",\n",
    "\"o'clock\": \"of the clock\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"oughtn't've\": \"ought not have\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"shan't've\": \"shall not have\",\n",
    "\"she'd\": \"she would\",\n",
    "\"she'd've\": \"she would have\",\n",
    "\"she'll\": \"she will\",\n",
    "\"she'll've\": \"she will have\",\n",
    "\"she's\": \"she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"shouldn't've\": \"should not have\",\n",
    "\"so've\": \"so have\",\n",
    "\"so's\": \"so as\",\n",
    "\"that'd\": \"that would\",\n",
    "\"that'd've\": \"that would have\",\n",
    "\"that's\": \"that is\",\n",
    "\"there'd\": \"there would\",\n",
    "\"there'd've\": \"there would have\",\n",
    "\"there's\": \"there is\",\n",
    "\"they'd\": \"they would\",\n",
    "\"they'd've\": \"they would have\",\n",
    "\"they'll\": \"they will\",\n",
    "\"they'll've\": \"they will have\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"to've\": \"to have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we would\",\n",
    "\"we'd've\": \"we would have\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we'll've\": \"we will have\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what will\",\n",
    "\"what'll've\": \"what will have\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"when's\": \"when is\",\n",
    "\"when've\": \"when have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where is\",\n",
    "\"where've\": \"where have\",\n",
    "\"who'll\": \"who will\",\n",
    "\"who'll've\": \"who will have\",\n",
    "\"who's\": \"who is\",\n",
    "\"who've\": \"who have\",\n",
    "\"why's\": \"why is\",\n",
    "\"why've\": \"why have\",\n",
    "\"will've\": \"will have\",\n",
    "\"won't\": \"will not\",\n",
    "\"won't've\": \"will not have\",\n",
    "\"would've\": \"would have\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"wouldn't've\": \"would not have\",\n",
    "\"y'all\": \"you all\",\n",
    "\"y'all'd\": \"you all would\",\n",
    "\"y'all'd've\": \"you all would have\",\n",
    "\"y'all're\": \"you all are\",\n",
    "\"y'all've\": \"you all have\",\n",
    "\"you'd\": \"you would\",\n",
    "\"you'd've\": \"you would have\",\n",
    "\"you'll\": \"you will\",\n",
    "\"you'll've\": \"you will have\",\n",
    "\"you're\": \"you are\",\n",
    "\"you've\": \"you have\",\n",
    "}\n",
    "# The code for expanding contraction words\n",
    "def expand_contractions(text, contraction_mapping =  CONTRACTION_MAP):\n",
    "    \"\"\"expand shortened words to the actual form.\n",
    "       e.g. don't to do not\n",
    "    \n",
    "       arguments:\n",
    "            input_text: \"text\" of type \"String\".\n",
    "         \n",
    "       return:\n",
    "            value: Text with expanded form of shorthened words.\n",
    "        \n",
    "       Example: \n",
    "       Input : ain't, aren't, can't, cause, can't've\n",
    "       Output :  is not, are not, cannot, because, cannot have \n",
    "    \n",
    "     \"\"\"\n",
    "    # Tokenizing text into tokens.\n",
    "    list_Of_tokens = text.split(' ')\n",
    "\n",
    "    # Checking for whether the given token matches with the Key & replacing word with key's value.\n",
    "    \n",
    "    # Check whether Word is in lidt_Of_tokens or not.\n",
    "    for Word in list_Of_tokens: \n",
    "        # Check whether found word is in dictionary \"Contraction Map\" or not as a key. \n",
    "         if Word in CONTRACTION_MAP: \n",
    "                # If Word is present in both dictionary & list_Of_tokens, replace that word with the key value.\n",
    "                list_Of_tokens = [item.replace(Word, CONTRACTION_MAP[Word]) for item in list_Of_tokens]\n",
    "                \n",
    "    # Converting list of tokens to String.\n",
    "    String_Of_tokens = ' '.join(str(e) for e in list_Of_tokens) \n",
    "    return String_Of_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b69c457b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rajup\\AppData\\Local\\Temp/ipykernel_14288/3518861763.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  X_train[feature] = X_train[feature].str.replace(r'[^\\w\\s]+', ' ')\n",
      "C:\\Users\\rajup\\AppData\\Local\\Temp/ipykernel_14288/3518861763.py:10: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  X_train[feature] = X_train[feature].str.replace('\\w*\\d+\\w*','NUM')\n",
      "C:\\Users\\rajup\\AppData\\Local\\Temp/ipykernel_14288/3518861763.py:11: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  X_train[feature] = X_train[feature].str.replace('\\s{2,}',' ')\n",
      "C:\\Users\\rajup\\AppData\\Local\\Temp/ipykernel_14288/3518861763.py:16: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  X_val[feature] = X_val[feature].str.replace(r'[^\\w\\s]+', ' ')\n",
      "C:\\Users\\rajup\\AppData\\Local\\Temp/ipykernel_14288/3518861763.py:18: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  X_val[feature] = X_val[feature].str.replace('\\w*\\d+\\w*','NUM')\n",
      "C:\\Users\\rajup\\AppData\\Local\\Temp/ipykernel_14288/3518861763.py:19: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  X_val[feature] = X_val[feature].str.replace('\\s{2,}',' ')\n",
      "C:\\Users\\rajup\\AppData\\Local\\Temp/ipykernel_14288/3518861763.py:24: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  X_test[feature] = X_test[feature].str.replace(r'[^\\w\\s]+', ' ')\n",
      "C:\\Users\\rajup\\AppData\\Local\\Temp/ipykernel_14288/3518861763.py:26: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  X_test[feature] = X_test[feature].str.replace('\\w*\\d+\\w*','NUM')\n",
      "C:\\Users\\rajup\\AppData\\Local\\Temp/ipykernel_14288/3518861763.py:27: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  X_test[feature] = X_test[feature].str.replace('\\s{2,}',' ')\n"
     ]
    }
   ],
   "source": [
    "#Punctuation deleting\n",
    "#Lowercase + strip\n",
    "#Numbers replacement with \"NUM\" token\n",
    "#Extra whitespaces removing\n",
    "txt_features = ['context', 'subject', 'speaker_job', 'Text']\n",
    "\n",
    "for feature in txt_features:\n",
    "    X_train[feature] = X_train[feature].str.replace(r'[^\\w\\s]+', ' ')\n",
    "    X_train[feature] = X_train[feature].apply(lambda x: x.lower().strip())\n",
    "    X_train[feature] = X_train[feature].str.replace('\\w*\\d+\\w*','NUM')\n",
    "    X_train[feature] = X_train[feature].str.replace('\\s{2,}',' ')\n",
    "    \n",
    "\n",
    "\n",
    "for feature in txt_features:\n",
    "    X_val[feature] = X_val[feature].str.replace(r'[^\\w\\s]+', ' ')\n",
    "    X_val[feature] = X_val[feature].apply(lambda x: x.lower().strip())\n",
    "    X_val[feature] = X_val[feature].str.replace('\\w*\\d+\\w*','NUM')\n",
    "    X_val[feature] = X_val[feature].str.replace('\\s{2,}',' ')\n",
    "    \n",
    "\n",
    "\n",
    "for feature in txt_features:\n",
    "    X_test[feature] = X_test[feature].str.replace(r'[^\\w\\s]+', ' ')\n",
    "    X_test[feature] = X_test[feature].apply(lambda x: x.lower().strip())\n",
    "    X_test[feature] = X_test[feature].str.replace('\\w*\\d+\\w*','NUM')\n",
    "    X_test[feature] = X_test[feature].str.replace('\\s{2,}',' ')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e4a99b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n",
      "58\n",
      "58\n",
      "42\n",
      "18\n",
      "59\n"
     ]
    }
   ],
   "source": [
    "print(X_train['subject'].value_counts().nunique())\n",
    "print(X_train['speaker'].value_counts().nunique())\n",
    "print(X_train['speaker_job'].value_counts().nunique())\n",
    "print(X_train['state'].value_counts().nunique())\n",
    "print(X_train['party'].value_counts().nunique())\n",
    "print(X_train['context'].value_counts().nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1aaff608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding subject,speaker,speaker job, state and party\n",
    "le_subj    = LabelEncoder()\n",
    "le_spkr    = LabelEncoder()\n",
    "le_spkr_jb = LabelEncoder()\n",
    "le_state   = LabelEncoder()\n",
    "le_prty    = LabelEncoder()\n",
    "le_ctxt    = LabelEncoder()\n",
    "\n",
    "X_train['subject'] = le_subj.fit_transform(X_train['subject'])\n",
    "X_train['speaker']   = le_spkr.fit_transform(X_train['speaker'])\n",
    "X_train['speaker_job']   = le_spkr_jb.fit_transform(X_train['speaker_job'])\n",
    "X_train['state']   = le_state.fit_transform(X_train['state'])\n",
    "X_train['party']   = le_prty.fit_transform(X_train['party'])\n",
    "X_train['context']   = le_ctxt.fit_transform(X_train['context'])\n",
    "\n",
    "X_val['subject'] = le_subj.fit_transform(X_val['subject'])\n",
    "X_val['speaker']   = le_spkr.fit_transform(X_val['speaker'])\n",
    "X_val['speaker_job']   = le_spkr_jb.fit_transform(X_val['speaker_job'])\n",
    "X_val['state']   = le_state.fit_transform(X_val['state'])\n",
    "X_val['party']   = le_prty.fit_transform(X_val['party'])\n",
    "X_val['context']   = le_ctxt.fit_transform(X_val['context'])\n",
    "\n",
    "X_test['subject'] = le_subj.fit_transform(X_test['subject'])\n",
    "X_test['speaker']   = le_spkr.fit_transform(X_test['speaker'])\n",
    "X_test['speaker_job']   = le_spkr_jb.fit_transform(X_test['speaker_job'])\n",
    "X_test['state']   = le_state.fit_transform(X_test['state'])\n",
    "X_test['party']   = le_prty.fit_transform(X_test['party'])\n",
    "X_test['context']   = le_ctxt.fit_transform(X_test['context'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3091000d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ----------------------- X Train Data ---------------------------- \n",
      "            subject  speaker  speaker_job  state  party  barely_true_counts  \\\n",
      "id_json                                                                       \n",
      "2635.json         2      814          954     58     19                 0.0   \n",
      "10540.json     2570     2491          943     62      5                 0.0   \n",
      "324.json       2862      182          722     20      5                70.0   \n",
      "1123.json      3074      272            0      0     16                 7.0   \n",
      "9028.json      2182      428            0     14      5                15.0   \n",
      "\n",
      "            false_counts  half_true_counts  mostly_true_counts  \\\n",
      "id_json                                                          \n",
      "2635.json            1.0               0.0                 0.0   \n",
      "10540.json           0.0               1.0                 1.0   \n",
      "324.json            71.0             160.0               163.0   \n",
      "1123.json           19.0               3.0                 5.0   \n",
      "9028.json            9.0              20.0                19.0   \n",
      "\n",
      "            pants_on_fire_counts  context  \\\n",
      "id_json                                     \n",
      "2635.json                    0.0      677   \n",
      "10540.json                   0.0      462   \n",
      "324.json                     9.0     3005   \n",
      "1123.json                   44.0      782   \n",
      "9028.json                    2.0     2277   \n",
      "\n",
      "                                                         Text  \n",
      "id_json                                                        \n",
      "2635.json   says the annies list political group supports ...  \n",
      "10540.json  when did the decline of coal start it started ...  \n",
      "324.json    hillary clinton agrees with john mccain by vot...  \n",
      "1123.json   health care reform legislation is likely to ma...  \n",
      "9028.json   the economic turnaround started at the end of ...  \n",
      " ----------------------- X Val Data   ------------------------------\n",
      "            subject  speaker  speaker_job  state  party  barely_true_counts  \\\n",
      "id_json                                                                       \n",
      "12134.json      343      646          267     23     14                   1   \n",
      "238.json        665       79            0      0     12                  11   \n",
      "7891.json        58      166          267     33      5                   0   \n",
      "8169.json       678      285          154     33     12                   0   \n",
      "929.json        366       36          188     13      5                  70   \n",
      "\n",
      "            false_counts  half_true_counts  mostly_true_counts  \\\n",
      "id_json                                                          \n",
      "12134.json             0                 1                   0   \n",
      "238.json              43                 8                   5   \n",
      "7891.json              1                 1                   1   \n",
      "8169.json              1                 1                   1   \n",
      "929.json              71               160                 163   \n",
      "\n",
      "            pants_on_fire_counts  context  \\\n",
      "id_json                                     \n",
      "12134.json                     0      473   \n",
      "238.json                     105        0   \n",
      "7891.json                      0      345   \n",
      "8169.json                      0      516   \n",
      "929.json                       9      639   \n",
      "\n",
      "                                                         Text  \n",
      "id_json                                                        \n",
      "12134.json  we have less americans working now than in the...  \n",
      "238.json    when obama was sworn into office he did not us...  \n",
      "7891.json   says having organizations parading as being so...  \n",
      "8169.json   says nearly half of oregons children are poor ...  \n",
      "929.json    on attacks by republicans that various program...  \n",
      " ----------------------- X Test Data  ------------------------------\n",
      "            subject  speaker  speaker_job  state  party  barely_true_counts  \\\n",
      "id_json                                                                       \n",
      "11972.json      592      509           97     38     13                  30   \n",
      "11685.json      620      339          228     48      5                   2   \n",
      "11096.json      666      166          176     29     13                  63   \n",
      "5209.json       649      513           64     32     13                   1   \n",
      "9524.json        75      566            0     48      5                   5   \n",
      "\n",
      "            false_counts  half_true_counts  mostly_true_counts  \\\n",
      "id_json                                                          \n",
      "11972.json            30                42                  23   \n",
      "11685.json             1                 0                   0   \n",
      "11096.json           114                51                  37   \n",
      "5209.json              1                 3                   1   \n",
      "9524.json              7                 2                   2   \n",
      "\n",
      "            pants_on_fire_counts  context  \\\n",
      "id_json                                     \n",
      "11972.json                    18      671   \n",
      "11685.json                     0      153   \n",
      "11096.json                    61      560   \n",
      "5209.json                      1      217   \n",
      "9524.json                      7      403   \n",
      "\n",
      "                                                         Text  \n",
      "id_json                                                        \n",
      "11972.json  building a wall on the u s mexico border will ...  \n",
      "11685.json  wisconsin is on pace to double the number of l...  \n",
      "11096.json  says john mccain has done nothing to help the ...  \n",
      "5209.json   suzanne bonamici supports a plan that will cut...  \n",
      "9524.json   when asked by a reporter whether hes at the ce...  \n"
     ]
    }
   ],
   "source": [
    "print(\" ----------------------- X Train Data ---------------------------- \")\n",
    "print(X_train.head())\n",
    "print(\" ----------------------- X Val Data   ------------------------------\")\n",
    "print(X_val.head())\n",
    "print(\" ----------------------- X Test Data  ------------------------------\")\n",
    "print(X_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f0a0f7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_idx = X_train.index\n",
    "X_val_idx   = X_val.index\n",
    "X_test_idx  = X_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3d4c5b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['11972.json', '11685.json', '11096.json', '5209.json', '9524.json',\n",
       "       '5962.json', '7070.json', '1046.json', '12849.json', '13270.json',\n",
       "       ...\n",
       "       '1005.json', '609.json', '9436.json', '5671.json', '6699.json',\n",
       "       '7334.json', '9788.json', '10710.json', '3186.json', '6743.json'],\n",
       "      dtype='object', name='id_json', length=1267)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ba7033c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import  LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.metrics import confusion_matrix, f1_score, classification_report\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "\n",
    "#from gensim.models.word2vec import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7862f706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count Vectorizer Implementation \n",
    "# create a count vectorizer objec\n",
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}',stop_words='english')\n",
    "count_vect.fit(X_train['Text'])\n",
    "# transform the training, testing and validation data using count vectorizer object\n",
    "X_train_count =  count_vect.transform(X_train['Text'])\n",
    "X_val_count   =  count_vect.transform(X_val['Text'])\n",
    "X_test_count  =  count_vect.transform(X_test['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1f825c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF IDF Implementation \n",
    "#\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
    "tfidf_vect.fit(X_train['Text'])\n",
    "X_train_tfidf =  tfidf_vect.transform(X_train['Text'])\n",
    "X_val_tfidf   =  tfidf_vect.transform(X_val['Text'])\n",
    "X_test_tfidf  =  tfidf_vect.transform(X_test['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dc08dce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_af = X_train[['subject', 'speaker', 'speaker_job', 'state', 'party',\n",
    "       'barely_true_counts', 'false_counts', 'half_true_counts',\n",
    "       'mostly_true_counts', 'pants_on_fire_counts', 'context']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "46185f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_af = X_val[['subject', 'speaker', 'speaker_job', 'state', 'party',\n",
    "       'barely_true_counts', 'false_counts', 'half_true_counts',\n",
    "       'mostly_true_counts', 'pants_on_fire_counts', 'context']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2c556cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_af = X_test[['subject', 'speaker', 'speaker_job', 'state', 'party',\n",
    "       'barely_true_counts', 'false_counts', 'half_true_counts',\n",
    "       'mostly_true_counts', 'pants_on_fire_counts', 'context']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "652cfc78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modelling\n",
    "#naive bayes classifier\n",
    "naive_bayes_classifier_count = MultinomialNB()\n",
    "naive_bayes_classifier_count.fit(X_train_count, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1036204c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions \n",
    "#predicted y\n",
    "y_pred_val_count = naive_bayes_classifier_count.predict(X_val_count)\n",
    "y_pred_test_count = naive_bayes_classifier_count.predict(X_test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e47b1369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.12      0.16       237\n",
      "           1       0.25      0.27      0.26       263\n",
      "           2       0.22      0.38      0.28       248\n",
      "           3       0.30      0.35      0.32       251\n",
      "           4       0.31      0.03      0.06       116\n",
      "           5       0.21      0.19      0.20       169\n",
      "\n",
      "    accuracy                           0.25      1284\n",
      "   macro avg       0.25      0.22      0.21      1284\n",
      "weighted avg       0.25      0.25      0.23      1284\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.15      0.18       212\n",
      "           1       0.23      0.23      0.23       249\n",
      "           2       0.22      0.36      0.27       265\n",
      "           3       0.19      0.19      0.19       241\n",
      "           4       0.42      0.09      0.14        92\n",
      "           5       0.18      0.16      0.17       208\n",
      "\n",
      "    accuracy                           0.21      1267\n",
      "   macro avg       0.25      0.20      0.20      1267\n",
      "weighted avg       0.23      0.21      0.21      1267\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Validation Metrics \n",
    "print(metrics.classification_report(Y_val, y_pred_val_count))\n",
    "# Test Metrics \n",
    "print(metrics.classification_report(Y_test, y_pred_test_count))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a226e804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes with tfidf\n",
    "\n",
    "naive_bayes_classifier_tfidf = MultinomialNB()\n",
    "naive_bayes_classifier_tfidf.fit(X_train_tfidf, Y_train)\n",
    "\n",
    "y_pred_val_tfidf = naive_bayes_classifier_tfidf.predict(X_val_tfidf)\n",
    "y_pred_test_tfidf = naive_bayes_classifier_tfidf.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6855c3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.04      0.07       237\n",
      "           1       0.28      0.35      0.31       263\n",
      "           2       0.22      0.51      0.30       248\n",
      "           3       0.26      0.31      0.28       251\n",
      "           4       0.00      0.00      0.00       116\n",
      "           5       0.22      0.05      0.08       169\n",
      "\n",
      "    accuracy                           0.25      1284\n",
      "   macro avg       0.21      0.21      0.17      1284\n",
      "weighted avg       0.23      0.25      0.20      1284\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.04      0.07       212\n",
      "           1       0.23      0.29      0.26       249\n",
      "           2       0.22      0.52      0.31       265\n",
      "           3       0.21      0.23      0.22       241\n",
      "           4       0.00      0.00      0.00        92\n",
      "           5       0.33      0.06      0.10       208\n",
      "\n",
      "    accuracy                           0.23      1267\n",
      "   macro avg       0.20      0.19      0.16      1267\n",
      "weighted avg       0.23      0.23      0.19      1267\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Validation Metrics \n",
    "print(metrics.classification_report(Y_val, y_pred_val_tfidf))\n",
    "# Test Metrics \n",
    "print(metrics.classification_report(Y_test, y_pred_test_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2b67e8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging additional features with vectors\n",
    "X_train_af_count   =  X_train_af.merge(pd.DataFrame(X_train_count.toarray(),index=X_train_idx),left_index=True, right_index=True\n",
    ")\n",
    "\n",
    "X_val_af_count    =  X_val_af.merge(pd.DataFrame(X_val_count.toarray(),index=X_val_idx),left_index=True, right_index=True\n",
    ")\n",
    "\n",
    "X_test_af_count   =  X_test_af.merge(pd.DataFrame(X_test_count.toarray(),index=X_test_idx),left_index=True, right_index=True\n",
    ")\n",
    "\n",
    "X_train_af_tfidf  =  X_train_af.merge(pd.DataFrame(X_train_tfidf.toarray(),index=X_train_idx),left_index=True, right_index=True\n",
    ")\n",
    "\n",
    "X_val_af_tfidf    =  X_val_af.merge(pd.DataFrame(X_val_tfidf.toarray(),index=X_val_idx),left_index=True, right_index=True\n",
    ")\n",
    "\n",
    "X_test_af_tfidf   =  X_test_af.merge(pd.DataFrame(X_test_tfidf.toarray(),index=X_test_idx),left_index=True, right_index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e38677c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speaker_job</th>\n",
       "      <th>state</th>\n",
       "      <th>party</th>\n",
       "      <th>barely_true_counts</th>\n",
       "      <th>false_counts</th>\n",
       "      <th>half_true_counts</th>\n",
       "      <th>mostly_true_counts</th>\n",
       "      <th>pants_on_fire_counts</th>\n",
       "      <th>...</th>\n",
       "      <th>4990</th>\n",
       "      <th>4991</th>\n",
       "      <th>4992</th>\n",
       "      <th>4993</th>\n",
       "      <th>4994</th>\n",
       "      <th>4995</th>\n",
       "      <th>4996</th>\n",
       "      <th>4997</th>\n",
       "      <th>4998</th>\n",
       "      <th>4999</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_json</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12134.json</th>\n",
       "      <td>343</td>\n",
       "      <td>646</td>\n",
       "      <td>267</td>\n",
       "      <td>23</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238.json</th>\n",
       "      <td>665</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>43</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>105</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7891.json</th>\n",
       "      <td>58</td>\n",
       "      <td>166</td>\n",
       "      <td>267</td>\n",
       "      <td>33</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8169.json</th>\n",
       "      <td>678</td>\n",
       "      <td>285</td>\n",
       "      <td>154</td>\n",
       "      <td>33</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929.json</th>\n",
       "      <td>366</td>\n",
       "      <td>36</td>\n",
       "      <td>188</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>70</td>\n",
       "      <td>71</td>\n",
       "      <td>160</td>\n",
       "      <td>163</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085665</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3419.json</th>\n",
       "      <td>435</td>\n",
       "      <td>36</td>\n",
       "      <td>188</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>70</td>\n",
       "      <td>71</td>\n",
       "      <td>160</td>\n",
       "      <td>163</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069787</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12548.json</th>\n",
       "      <td>72</td>\n",
       "      <td>240</td>\n",
       "      <td>202</td>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>29</td>\n",
       "      <td>69</td>\n",
       "      <td>76</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401.json</th>\n",
       "      <td>543</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055.json</th>\n",
       "      <td>543</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.183598</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9117.json</th>\n",
       "      <td>103</td>\n",
       "      <td>550</td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1284 rows  5011 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            subject  speaker  speaker_job  state  party  barely_true_counts  \\\n",
       "id_json                                                                       \n",
       "12134.json      343      646          267     23     14                   1   \n",
       "238.json        665       79            0      0     12                  11   \n",
       "7891.json        58      166          267     33      5                   0   \n",
       "8169.json       678      285          154     33     12                   0   \n",
       "929.json        366       36          188     13      5                  70   \n",
       "...             ...      ...          ...    ...    ...                 ...   \n",
       "3419.json       435       36          188     13      5                  70   \n",
       "12548.json       72      240          202     28      5                  40   \n",
       "401.json        543       73            0     43     12                   0   \n",
       "1055.json       543       22            0      0     12                   1   \n",
       "9117.json       103      550            8     28     14                   9   \n",
       "\n",
       "            false_counts  half_true_counts  mostly_true_counts  \\\n",
       "id_json                                                          \n",
       "12134.json             0                 1                   0   \n",
       "238.json              43                 8                   5   \n",
       "7891.json              1                 1                   1   \n",
       "8169.json              1                 1                   1   \n",
       "929.json              71               160                 163   \n",
       "...                  ...               ...                 ...   \n",
       "3419.json             71               160                 163   \n",
       "12548.json            29                69                  76   \n",
       "401.json               1                 0                   2   \n",
       "1055.json              4                 4                   1   \n",
       "9117.json             11                10                   7   \n",
       "\n",
       "            pants_on_fire_counts  ...      4990  4991  4992  4993  4994  4995  \\\n",
       "id_json                           ...                                           \n",
       "12134.json                     0  ...  0.000000   0.0   0.0   0.0   0.0   0.0   \n",
       "238.json                     105  ...  0.000000   0.0   0.0   0.0   0.0   0.0   \n",
       "7891.json                      0  ...  0.000000   0.0   0.0   0.0   0.0   0.0   \n",
       "8169.json                      0  ...  0.068154   0.0   0.0   0.0   0.0   0.0   \n",
       "929.json                       9  ...  0.085665   0.0   0.0   0.0   0.0   0.0   \n",
       "...                          ...  ...       ...   ...   ...   ...   ...   ...   \n",
       "3419.json                      9  ...  0.069787   0.0   0.0   0.0   0.0   0.0   \n",
       "12548.json                     7  ...  0.000000   0.0   0.0   0.0   0.0   0.0   \n",
       "401.json                       0  ...  0.000000   0.0   0.0   0.0   0.0   0.0   \n",
       "1055.json                      0  ...  0.183598   0.0   0.0   0.0   0.0   0.0   \n",
       "9117.json                      3  ...  0.000000   0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "            4996  4997  4998  4999  \n",
       "id_json                             \n",
       "12134.json   0.0   0.0   0.0   0.0  \n",
       "238.json     0.0   0.0   0.0   0.0  \n",
       "7891.json    0.0   0.0   0.0   0.0  \n",
       "8169.json    0.0   0.0   0.0   0.0  \n",
       "929.json     0.0   0.0   0.0   0.0  \n",
       "...          ...   ...   ...   ...  \n",
       "3419.json    0.0   0.0   0.0   0.0  \n",
       "12548.json   0.0   0.0   0.0   0.0  \n",
       "401.json     0.0   0.0   0.0   0.0  \n",
       "1055.json    0.0   0.0   0.0   0.0  \n",
       "9117.json    0.0   0.0   0.0   0.0  \n",
       "\n",
       "[1284 rows x 5011 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_af_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8fcaff87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes with count vector with additional features\n",
    "\n",
    "naive_bayes_classifier_count_af = MultinomialNB()\n",
    "naive_bayes_classifier_count_af.fit(X_train_af_count, Y_train)\n",
    "\n",
    "y_pred_val_count_af    = naive_bayes_classifier_count_af.predict(X_val_af_count)\n",
    "y_pred_test_count_af   = naive_bayes_classifier_count_af.predict(X_test_af_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "51998f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.16      0.18       237\n",
      "           1       0.26      0.10      0.14       263\n",
      "           2       0.21      0.09      0.13       248\n",
      "           3       0.26      0.33      0.29       251\n",
      "           4       0.17      0.51      0.25       116\n",
      "           5       0.17      0.22      0.19       169\n",
      "\n",
      "    accuracy                           0.21      1284\n",
      "   macro avg       0.21      0.24      0.20      1284\n",
      "weighted avg       0.22      0.21      0.19      1284\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.11      0.13       212\n",
      "           1       0.25      0.10      0.15       249\n",
      "           2       0.25      0.12      0.16       265\n",
      "           3       0.25      0.36      0.30       241\n",
      "           4       0.14      0.48      0.22        92\n",
      "           5       0.23      0.25      0.24       208\n",
      "\n",
      "    accuracy                           0.21      1267\n",
      "   macro avg       0.21      0.24      0.20      1267\n",
      "weighted avg       0.22      0.21      0.20      1267\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Validation Metrics \n",
    "print(metrics.classification_report(Y_val, y_pred_val_count_af))\n",
    "# Test Metrics \n",
    "print(metrics.classification_report(Y_test, y_pred_test_count_af))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "861e1047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes with tfidf with additional features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "88979c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_bayes_classifier_tfidf_af = MultinomialNB()\n",
    "naive_bayes_classifier_tfidf_af.fit(X_train_af_tfidf, Y_train)\n",
    "\n",
    "y_pred_val_tfidf_af    = naive_bayes_classifier_tfidf_af.predict(X_val_af_tfidf)\n",
    "y_pred_test_tfidf_af   = naive_bayes_classifier_tfidf_af.predict(X_test_af_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bda98fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************  Validation Report  ********************************\n",
      "[[34 24 18 44 71 46]\n",
      " [42 25 18 44 80 54]\n",
      " [30 22 20 60 55 61]\n",
      " [35 13 14 65 63 61]\n",
      " [10 16  7 13 53 17]\n",
      " [25 11 11 42 42 38]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.14      0.16       237\n",
      "           1       0.23      0.10      0.13       263\n",
      "           2       0.23      0.08      0.12       248\n",
      "           3       0.24      0.26      0.25       251\n",
      "           4       0.15      0.46      0.22       116\n",
      "           5       0.14      0.22      0.17       169\n",
      "\n",
      "    accuracy                           0.18      1284\n",
      "   macro avg       0.20      0.21      0.18      1284\n",
      "weighted avg       0.20      0.18      0.17      1284\n",
      "\n",
      "****************************  Test Report  **************************************\n",
      "[[21 17 20 37 73 44]\n",
      " [41 34 28 39 62 45]\n",
      " [32 19 32 71 56 55]\n",
      " [29 19 18 67 50 58]\n",
      " [13  9  3 11 42 14]\n",
      " [29 13 15 58 39 54]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      0.10      0.11       212\n",
      "           1       0.31      0.14      0.19       249\n",
      "           2       0.28      0.12      0.17       265\n",
      "           3       0.24      0.28      0.26       241\n",
      "           4       0.13      0.46      0.20        92\n",
      "           5       0.20      0.26      0.23       208\n",
      "\n",
      "    accuracy                           0.20      1267\n",
      "   macro avg       0.21      0.23      0.19      1267\n",
      "weighted avg       0.23      0.20      0.19      1267\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Validation Metrics \n",
    "print(\"****************************  Validation Report  ********************************\")\n",
    "print(confusion_matrix(Y_val, y_pred_val_tfidf_af))\n",
    "print(metrics.classification_report(Y_val, y_pred_val_tfidf_af))\n",
    "# Test Metrics \n",
    "print(\"****************************  Test Report  **************************************\")\n",
    "print(confusion_matrix(Y_test, y_pred_test_tfidf_af))\n",
    "print(metrics.classification_report(Y_test, y_pred_test_tfidf_af))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d1323a0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_depth=6, min_samples_split=16)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree TPOT Pipeline given parameters from Count Vectorizer with af\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt_count_af = DecisionTreeClassifier(criterion=\"entropy\", max_depth=6, min_samples_leaf=1, min_samples_split=16)\n",
    "dt_count_af.fit(X_train_af_count, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f29abfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_val_dt_count_af    = dt_count_af.predict(X_val_af_count)\n",
    "y_pred_test_dt_count_af   = dt_count_af.predict(X_test_af_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "93d3e616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************  Validation Report  ********************************\n",
      "[[ 45  86  17  79  10   0]\n",
      " [  0 146   1  96  20   0]\n",
      " [  0  53  70 113  11   1]\n",
      " [  8  40  11 184   8   0]\n",
      " [  0  33   0  26  55   2]\n",
      " [  4  48   9  70   6  32]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.19      0.31       237\n",
      "           1       0.36      0.56      0.44       263\n",
      "           2       0.65      0.28      0.39       248\n",
      "           3       0.32      0.73      0.45       251\n",
      "           4       0.50      0.47      0.49       116\n",
      "           5       0.91      0.19      0.31       169\n",
      "\n",
      "    accuracy                           0.41      1284\n",
      "   macro avg       0.59      0.40      0.40      1284\n",
      "weighted avg       0.57      0.41      0.39      1284\n",
      "\n",
      "****************************  Test Report  **************************************\n",
      "[[ 45  71  11  72  12   1]\n",
      " [  0 143   1  85  17   3]\n",
      " [  1  60  56 136  10   2]\n",
      " [  6  38  13 179   5   0]\n",
      " [  1  33   1   8  48   1]\n",
      " [  9  46  15  99   8  31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.21      0.33       212\n",
      "           1       0.37      0.57      0.45       249\n",
      "           2       0.58      0.21      0.31       265\n",
      "           3       0.31      0.74      0.44       241\n",
      "           4       0.48      0.52      0.50        92\n",
      "           5       0.82      0.15      0.25       208\n",
      "\n",
      "    accuracy                           0.40      1267\n",
      "   macro avg       0.55      0.40      0.38      1267\n",
      "weighted avg       0.54      0.40      0.37      1267\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Validation Metrics \n",
    "print(\"****************************  Validation Report  ********************************\")\n",
    "print(confusion_matrix(Y_val, y_pred_val_dt_count_af))\n",
    "print(metrics.classification_report(Y_val, y_pred_val_dt_count_af))\n",
    "# Test Metrics \n",
    "print(\"****************************  Test Report  **************************************\")\n",
    "print(confusion_matrix(Y_test, y_pred_test_dt_count_af))\n",
    "print(metrics.classification_report(Y_test, y_pred_test_dt_count_af))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1566e695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_depth=6, min_samples_split=16)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree TPOT Pipeline given parameters from tfidf with af\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt_tfidf_af = DecisionTreeClassifier(criterion=\"entropy\", max_depth=6, min_samples_leaf=1, min_samples_split=16)\n",
    "dt_tfidf_af.fit(X_train_af_tfidf, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "af142c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_val_dt_tfidf_af    = dt_tfidf_af.predict(X_val_af_tfidf)\n",
    "y_pred_test_dt_tfidf_af   = dt_tfidf_af.predict(X_test_af_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "90ceafae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Having Labels instead of Label Encoding \n",
    "Y_test_inv = le.inverse_transform(Y_test)\n",
    "Y_val_inv = le.inverse_transform(Y_val)\n",
    "y_pred_val_dt_count_af_inv = le.inverse_transform(y_pred_val_dt_count_af)\n",
    "y_pred_test_dt_count_af_inv = le.inverse_transform(y_pred_test_dt_count_af)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "86c0d920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************  Validation Report  ********************************\n",
      "[[ 45  86  17  79  10   0]\n",
      " [  0 146   1  96  20   0]\n",
      " [  0  53  70 113  11   1]\n",
      " [  8  40  11 184   8   0]\n",
      " [  0  33   0  26  55   2]\n",
      " [  4  48   9  70   6  32]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " barely-true       0.79      0.19      0.31       237\n",
      "       false       0.36      0.56      0.44       263\n",
      "   half-true       0.65      0.28      0.39       248\n",
      " mostly-true       0.32      0.73      0.45       251\n",
      "  pants-fire       0.50      0.47      0.49       116\n",
      "        true       0.91      0.19      0.31       169\n",
      "\n",
      "    accuracy                           0.41      1284\n",
      "   macro avg       0.59      0.40      0.40      1284\n",
      "weighted avg       0.57      0.41      0.39      1284\n",
      "\n",
      "****************************  Test Report  **************************************\n",
      "[[ 45  71  11  72  12   1]\n",
      " [  0 143   1  85  17   3]\n",
      " [  1  60  56 136  10   2]\n",
      " [  6  38  13 179   5   0]\n",
      " [  1  33   1   8  48   1]\n",
      " [  9  46  15  99   8  31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " barely-true       0.73      0.21      0.33       212\n",
      "       false       0.37      0.57      0.45       249\n",
      "   half-true       0.58      0.21      0.31       265\n",
      " mostly-true       0.31      0.74      0.44       241\n",
      "  pants-fire       0.48      0.52      0.50        92\n",
      "        true       0.82      0.15      0.25       208\n",
      "\n",
      "    accuracy                           0.40      1267\n",
      "   macro avg       0.55      0.40      0.38      1267\n",
      "weighted avg       0.54      0.40      0.37      1267\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Validation Metrics \n",
    "print(\"****************************  Validation Report  ********************************\")\n",
    "print(confusion_matrix(Y_val_inv, y_pred_val_dt_count_af_inv))\n",
    "print(metrics.classification_report(Y_val_inv, y_pred_val_dt_count_af_inv))\n",
    "# Test Metrics \n",
    "print(\"****************************  Test Report  **************************************\")\n",
    "print(confusion_matrix(Y_test_inv, y_pred_test_dt_count_af_inv))\n",
    "print(metrics.classification_report(Y_test_inv, y_pred_test_dt_count_af_inv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d422ad31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Having Labels instead of Label Encoding \n",
    "Y_test_inv = le.inverse_transform(Y_test)\n",
    "Y_val_inv = le.inverse_transform(Y_val)\n",
    "y_pred_val_dt_tfidf_af_inv = le.inverse_transform(y_pred_val_dt_tfidf_af)\n",
    "y_pred_test_dt_tfidf_af_inv = le.inverse_transform(y_pred_test_dt_tfidf_af)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "70af1f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************  Validation Report  ********************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " barely-true       0.66      0.27      0.39       237\n",
      "       false       0.36      0.56      0.44       263\n",
      "   half-true       0.72      0.24      0.36       248\n",
      " mostly-true       0.33      0.74      0.45       251\n",
      "  pants-fire       0.51      0.42      0.46       116\n",
      "        true       0.94      0.19      0.32       169\n",
      "\n",
      "    accuracy                           0.42      1284\n",
      "   macro avg       0.59      0.40      0.40      1284\n",
      "weighted avg       0.57      0.42      0.40      1284\n",
      "\n",
      "****************************  Test Report  **************************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " barely-true       0.62      0.26      0.37       212\n",
      "       false       0.37      0.56      0.44       249\n",
      "   half-true       0.59      0.18      0.28       265\n",
      " mostly-true       0.31      0.74      0.44       241\n",
      "  pants-fire       0.45      0.47      0.46        92\n",
      "        true       0.76      0.16      0.27       208\n",
      "\n",
      "    accuracy                           0.39      1267\n",
      "   macro avg       0.52      0.40      0.38      1267\n",
      "weighted avg       0.51      0.39      0.37      1267\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Validation Metrics \n",
    "print(\"****************************  Validation Report  ********************************\")\n",
    "print(metrics.classification_report(Y_val_inv, y_pred_val_dt_tfidf_af_inv))\n",
    "# Test Metrics \n",
    "print(\"****************************  Test Report  **************************************\")\n",
    "print(metrics.classification_report(Y_test_inv, y_pred_test_dt_tfidf_af_inv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0d69357a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing pytorch GPU \n",
    "import torch\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0c0396c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 2060'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking GPU \n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c1f75251",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install TPOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c728e4e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, ..., 2, 1, 4])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9b5509f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpot import TPOTClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d10e91ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e9c2a331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39a7d35fe55e4d42bdfe432aec895761",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/50 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "TPOT closed during evaluation in one generation.\n",
      "WARNING: TPOT may not provide a good pipeline if TPOT is stopped/interrupted in a early generation.\n",
      "\n",
      "\n",
      "TPOT closed prematurely. Will use the current best pipeline.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "There was an error in the TPOT optimization process. This could be because the data was not formatted properly, or because data for a regression problem was provided to the TPOTClassifier object. Please make sure you passed the data to TPOT correctly. If you enabled PyTorch estimators, please check the data requirements in the online documentation: https://epistasislab.github.io/tpot/using/",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14288/1239883081.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Tune Generations or max_time_mins for the pipeline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtpot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTPOTClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_time_mins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpopulation_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbosity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig_dict\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;34m'TPOT NN'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarm_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtpot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_af_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtpot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_af_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tpot\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, features, target, sample_weight, groups)\u001b[0m\n\u001b[0;32m    861\u001b[0m                     \u001b[1;31m# raise the exception if it's our last attempt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mattempt\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mattempts\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 863\u001b[1;33m                         \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    864\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tpot\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, features, target, sample_weight, groups)\u001b[0m\n\u001b[0;32m    852\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    853\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 854\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_top_pipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    855\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_summary_of_best_pipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    856\u001b[0m                     \u001b[1;31m# Delete the temporary cache before exiting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tpot\\base.py\u001b[0m in \u001b[0;36m_update_top_pipeline\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    932\u001b[0m                         )\n\u001b[0;32m    933\u001b[0m                         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 934\u001b[1;33m                 raise RuntimeError(\n\u001b[0m\u001b[0;32m    935\u001b[0m                     \u001b[1;34m\"There was an error in the TPOT optimization \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    936\u001b[0m                     \u001b[1;34m\"process. This could be because the data was \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: There was an error in the TPOT optimization process. This could be because the data was not formatted properly, or because data for a regression problem was provided to the TPOTClassifier object. Please make sure you passed the data to TPOT correctly. If you enabled PyTorch estimators, please check the data requirements in the online documentation: https://epistasislab.github.io/tpot/using/"
     ]
    }
   ],
   "source": [
    "# Tune Generations or max_time_mins for the pipeline\n",
    "tpot = TPOTClassifier(max_time_mins=20, population_size=50, verbosity=2, random_state=42, cv= cv, scoring='accuracy', config_dict ='TPOT NN', warm_start=True)\n",
    "tpot.fit(X_train_af_count, Y_train)\n",
    "print(tpot.score(X_test_af_count, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7e700a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tpot.score(X_test_af_count, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a4c5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tpot.score(X_val_af_count, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "42471951",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "A pipeline has not yet been optimized. Please call fit() first.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14288/2181671747.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtpot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tpot_test_sample.py'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tpot\\base.py\u001b[0m in \u001b[0;36mexport\u001b[1;34m(self, output_file_name, data_file_path)\u001b[0m\n\u001b[0;32m   1278\u001b[0m         \"\"\"\n\u001b[0;32m   1279\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_optimized_pipeline\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1280\u001b[1;33m             raise RuntimeError(\n\u001b[0m\u001b[0;32m   1281\u001b[0m                 \u001b[1;34m\"A pipeline has not yet been optimized. Please call fit() first.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1282\u001b[0m             )\n",
      "\u001b[1;31mRuntimeError\u001b[0m: A pipeline has not yet been optimized. Please call fit() first."
     ]
    }
   ],
   "source": [
    "tpot.export('tpot_test_sample.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953a9223",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a826e1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implemenation of TFIDF with TPOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191cae41",
   "metadata": {},
   "outputs": [],
   "source": [
    "tpot_tfidf = TPOTClassifier(max_time_mins=150, population_size=50, verbosity=3, random_state=42, cv= cv, scoring='accuracy', config_dict ='TPOT NN', warm_start=True,n_jobs=8)\n",
    "tpot_tfidf.fit(X_train_af_tfidf, Y_train)\n",
    "print(tpot_tfidf.score(X_test_af_tfidf, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67398312",
   "metadata": {},
   "outputs": [],
   "source": [
    "tpot_tfidf.export('tpot_exported_pipeline_tfidf.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1d3b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Glove Vectors\n",
    "import os\n",
    "import tqdm\n",
    "import requests\n",
    "import zipfile\n",
    "URL = \"http://nlp.stanford.edu/data/glove.42B.300d.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee2fbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_extract_data(web_url=URL, target_file='glove.zip', delete_zip=False):\n",
    "    #if the dataset already exists exit\n",
    "    if os.path.isfile(target_file):\n",
    "        print(\"datasets already downloded :) \")\n",
    "        return\n",
    "\n",
    "    \n",
    "    print(\"**************************\")\n",
    "    print(\"  Downloading zip file\")\n",
    "    print(\"  >_<  Please wait >_< \")\n",
    "    print(\"**************************\")\n",
    "    response = requests.get(web_url, stream=True)\n",
    "    #read chunk by chunk\n",
    "    handle = open(target_file, \"wb\")\n",
    "    for chunk in tqdm.tqdm(response.iter_content(chunk_size=512)):\n",
    "        if chunk:  \n",
    "            handle.write(chunk)\n",
    "    handle.close()  \n",
    "    print(\"  Download completed ;) :\") \n",
    "    #extract zip_file\n",
    "    zf = zipfile.ZipFile(target_file)\n",
    "    print(\"1. Extracting {} file\".format(target_file))\n",
    "    zf.extractall()\n",
    "    if delete_zip:\n",
    "        print(\"2. Deleting {} file\".format(dataset_name+\".zip\"))\n",
    "        os.remove(path=zip_file)\n",
    "\n",
    "download_extract_data(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de10899b",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_file = 'glove.42B.300d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc3c6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e935161",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51824b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample change "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
