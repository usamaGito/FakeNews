{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we first load the glove vectors as a dictionary - `embeddings_index`\n",
    "`embeddings_index['banana']` would give some 100 length vector for the word `'banana'`\n",
    "\n",
    "The object `GLOVE_DIR` points to the text file which containes the vectors, but it could also be downloaded form http://nlp.stanford.edu/data/glove.6B.zip and saved on disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing word vectors.\n",
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "GLOVE_DIR = '/home/datasets/glove.6B/'\n",
    "\n",
    "print('Indexing word vectors.')\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join(GLOVE_DIR, 'glove.6B.100d.txt'))\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's find the top 7 words that are closest to Sunday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000\n"
     ]
    }
   ],
   "source": [
    "u = embeddings_index['compute']\n",
    "norm_u = np.linalg.norm(u)\n",
    "similarity = []\n",
    "\n",
    "\n",
    "for word in embeddings_index.keys():\n",
    "    v = embeddings_index[word]\n",
    "    cosine = np.dot(u, v)/norm_u/np.linalg.norm(v)\n",
    "    similarity.append((word, cosine))\n",
    "\n",
    "\n",
    "print(len(similarity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('compute', 1.0),\n",
       " ('calculate', 0.72220618),\n",
       " ('algorithm', 0.64410579),\n",
       " ('computed', 0.61362344),\n",
       " ('algorithms', 0.61343831),\n",
       " ('equivalently', 0.59991407),\n",
       " ('formula_1', 0.5970425),\n",
       " ('formula_2', 0.59485167),\n",
       " ('formula_3', 0.59312898),\n",
       " ('formula_5', 0.59209329)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(similarity, key=lambda x: x[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's do vector algebra.\n",
    "\n",
    "### First we subtract the vector for `italy` from `paris`. This could be imagined as a vector pointing from country to its capital. Then we add the vector of `nepal`. Let's see if it does point to the country's capital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000\n"
     ]
    }
   ],
   "source": [
    "output = embeddings_index['queen'] - embeddings_index['king'] + embeddings_index['man']\n",
    "norm_out = np.linalg.norm(u)\n",
    "\n",
    "similarity = []\n",
    "for word in embeddings_index.keys():\n",
    "    v = embeddings_index[word]\n",
    "    cosine = np.dot(output, v)/norm_out/np.linalg.norm(v)\n",
    "    similarity.append((word, cosine))\n",
    "\n",
    "\n",
    "print(len(similarity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('woman', 1.1351414),\n",
       " ('man', 1.1000676),\n",
       " ('girl', 1.037657),\n",
       " ('she', 0.96262932),\n",
       " ('her', 0.93075562),\n",
       " ('mother', 0.92366594),\n",
       " ('boy', 0.91029704)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(similarity, key=lambda x: x[1], reverse=True)[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.23191001,  0.61425   ,  0.72978997, -0.56645   , -0.34542999,\n",
       "        0.0035128 , -0.24593   ,  0.25248   , -0.18366   , -0.21272001,\n",
       "       -0.066142  , -0.17658   ,  0.43088001,  0.065273  ,  0.1621    ,\n",
       "        0.31865001,  0.017354  ,  0.54931003, -0.020546  ,  0.37718999,\n",
       "        0.081528  ,  0.29773   , -0.13805   , -0.39225   ,  0.014614  ,\n",
       "        0.018266  , -0.1661    , -0.83392   , -0.14606   , -0.51199001,\n",
       "        0.13350999,  0.15918   , -0.21639   , -0.19966   ,  0.36950001,\n",
       "        0.36482999, -0.36995   , -0.17254999,  0.21675   , -0.37445   ,\n",
       "       -0.0090887 , -0.56870002, -0.2499    , -0.41793001, -0.74956   ,\n",
       "        0.177     ,  0.084483  ,  0.36882001,  0.11713   , -1.07780004,\n",
       "        0.31172001, -0.094204  , -0.060947  ,  1.0474    , -0.098987  ,\n",
       "       -2.51880002,  0.12349   ,  0.25422001,  1.39339995, -0.027555  ,\n",
       "       -0.43748999,  1.52740002, -0.53972   , -0.027559  ,  0.91613001,\n",
       "       -0.01512   ,  0.46156999,  0.59706998, -0.57489997, -0.17486   ,\n",
       "        0.59455001, -0.22697   , -0.29840001, -0.88810003,  0.2421    ,\n",
       "       -0.18961   , -0.08277   ,  0.17992   ,  0.014689  , -0.57893002,\n",
       "        0.39838001,  0.15372001, -0.20716   ,  0.0095436 , -1.24349999,\n",
       "       -0.73986   , -0.10848   , -0.12868001, -0.60982001, -0.28507   ,\n",
       "        0.352     , -0.009741  ,  0.15383001, -0.64238   , -0.35341999,\n",
       "       -0.15507001, -0.65261   , -0.30781999,  0.24977   ,  0.48365   ], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_index['look']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
